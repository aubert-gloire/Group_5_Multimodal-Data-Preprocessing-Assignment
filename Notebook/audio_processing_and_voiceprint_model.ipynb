{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8adb2c0",
   "metadata": {},
   "source": [
    "# Audio Data Collection and Voiceprint Verification Model\n",
    "## Formative 2: Multimodal Data Preprocessing Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ddb19",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Libraries imported | Librosa version: {librosa.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd391746",
   "metadata": {},
   "source": [
    "## 2. Directory Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(r'c:\\Users\\evotech\\Documents\\MACHINE LEARNING PROJECTS\\Group_5_Multimodal-Data-Preprocessing-Assignment')\n",
    "audio_dir = base_dir / 'Dataset' / 'audio_samples'\n",
    "original_dir = audio_dir / 'original'\n",
    "augmented_dir = audio_dir / 'augmented'\n",
    "unauthorized_dir = audio_dir / 'unauthorized'\n",
    "\n",
    "original_dir.mkdir(parents=True, exist_ok=True)\n",
    "augmented_dir.mkdir(parents=True, exist_ok=True)\n",
    "unauthorized_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directories ready:\\n   Original: {original_dir}\\n   Augmented: {augmented_dir}\\n   Unauthorized: {unauthorized_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeef46f",
   "metadata": {},
   "source": [
    "## 3. Load Audio Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = list(original_dir.glob('*.wav'))\n",
    "audio_data = []\n",
    "\n",
    "print(f\"Found {len(audio_files)} audio files:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for audio_file in sorted(audio_files):\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    filename = audio_file.stem\n",
    "    parts = filename.split('_')\n",
    "    member = parts[0] if len(parts) > 0 else filename.split('-')[0] if '-' in filename else 'unknown'\n",
    "    phrase = '_'.join(parts[1:]) if len(parts) > 1 else filename\n",
    "    \n",
    "    audio_data.append({\n",
    "        'filename': audio_file.name,\n",
    "        'member': member,\n",
    "        'phrase': phrase,\n",
    "        'sample_rate': sr,\n",
    "        'duration': duration,\n",
    "        'samples': len(y),\n",
    "        'audio': y,\n",
    "        'path': str(audio_file)\n",
    "    })\n",
    "    \n",
    "    print(f\"{audio_file.name} | {member} | {sr} Hz | {duration:.2f}s\")\n",
    "\n",
    "print(f\"\\nLoaded {len(audio_data)} audio samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde6547",
   "metadata": {},
   "source": [
    "## 4. Audio Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20995d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(audio_path, member_name, phrase):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    librosa.display.waveshow(y, sr=sr, ax=axes[0], color='blue', alpha=0.7)\n",
    "    axes[0].set_title(f'Waveform: {member_name} - \"{phrase}\"', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Time (seconds)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1], cmap='viridis')\n",
    "    axes[1].set_title(f'Spectrogram: {member_name} - \"{phrase}\"', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time (seconds)')\n",
    "    axes[1].set_ylabel('Frequency (Hz)')\n",
    "    fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Analysis for {member_name} - '{phrase}':\")\n",
    "    print(f\"   Duration: {len(y)/sr:.2f}s | Max Amplitude: {np.max(np.abs(y)):.4f}\")\n",
    "    print(f\"   RMS Energy: {np.sqrt(np.mean(y**2)):.4f} | ZCR: {np.mean(librosa.zero_crossings(y)):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUDIO VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for data in audio_data:\n",
    "    visualize_audio(data['path'], data['member'], data['phrase'])\n",
    "    print(\"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f270bea",
   "metadata": {},
   "source": [
    "## 5. Audio Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(y, sr, n_steps=2):\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def time_stretch(y, rate=1.2):\n",
    "    return librosa.effects.time_stretch(y, rate=rate)\n",
    "\n",
    "def add_noise(y, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(y))\n",
    "    return y + noise_factor * noise\n",
    "\n",
    "def change_volume(y, factor=0.7):\n",
    "    return y * factor\n",
    "\n",
    "print(\"Augmentation functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying Augmentations...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "augmented_data = []\n",
    "\n",
    "for data in audio_data:\n",
    "    y, sr = data['audio'], data['sample_rate']\n",
    "    member, phrase = data['member'], data['phrase']\n",
    "    base_filename = f\"{member}_{phrase}\"\n",
    "    \n",
    "    augmentations = [\n",
    "        (pitch_shift(y, sr, n_steps=2), 'pitch_up'),\n",
    "        (time_stretch(y, rate=1.2), 'faster'),\n",
    "        (add_noise(y, noise_factor=0.005), 'noise'),\n",
    "        (change_volume(y, factor=0.7), 'volume_low')\n",
    "    ]\n",
    "    \n",
    "    for aug_audio, aug_type in augmentations:\n",
    "        aug_path = augmented_dir / f\"{base_filename}_{aug_type}.wav\"\n",
    "        sf.write(aug_path, aug_audio, sr)\n",
    "        augmented_data.append({\n",
    "            'original_file': data['filename'],\n",
    "            'member': member,\n",
    "            'phrase': phrase,\n",
    "            'augmentation': aug_type,\n",
    "            'audio': aug_audio,\n",
    "            'sample_rate': sr,\n",
    "            'path': str(aug_path)\n",
    "        })\n",
    "    \n",
    "    print(f\"[OK] {data['filename']}: 4 augmentations created\")\n",
    "\n",
    "print(f\"\\nTotal: {len(audio_data)} original + {len(augmented_data)} augmented = {len(audio_data) + len(augmented_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f57a5",
   "metadata": {},
   "source": [
    "## 6. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc559fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(y, sr):\n",
    "    features = {}\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    for i in range(13):\n",
    "        features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])\n",
    "        features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])\n",
    "    \n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)\n",
    "    features['spectral_rolloff_std'] = np.std(spectral_rolloff)\n",
    "    \n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features['rms_energy_mean'] = np.mean(rms)\n",
    "    features['rms_energy_std'] = np.std(rms)\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features['zero_crossing_rate_mean'] = np.mean(zcr)\n",
    "    features['zero_crossing_rate_std'] = np.std(zcr)\n",
    "    \n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    features['spectral_centroid_mean'] = np.mean(spectral_centroid)\n",
    "    features['spectral_centroid_std'] = np.std(spectral_centroid)\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features['chroma_mean'] = np.mean(chroma)\n",
    "    features['chroma_std'] = np.std(chroma)\n",
    "    \n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)\n",
    "    features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Feature extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting Features...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for data in audio_data:\n",
    "    features = extract_audio_features(data['audio'], data['sample_rate'])\n",
    "    features.update({\n",
    "        'filename': data['filename'],\n",
    "        'member': data['member'],\n",
    "        'phrase': data['phrase'],\n",
    "        'augmentation': 'original',\n",
    "        'is_authorized': 1\n",
    "    })\n",
    "    all_features.append(features)\n",
    "\n",
    "for data in augmented_data:\n",
    "    features = extract_audio_features(data['audio'], data['sample_rate'])\n",
    "    features.update({\n",
    "        'filename': Path(data['path']).name,\n",
    "        'member': data['member'],\n",
    "        'phrase': data['phrase'],\n",
    "        'augmentation': data['augmentation'],\n",
    "        'is_authorized': 1\n",
    "    })\n",
    "    all_features.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(all_features)\n",
    "\n",
    "print(f\"Features extracted: {features_df.shape[0]} samples x {features_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b910e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Sample:\")\n",
    "print(\"=\" * 70)\n",
    "display(features_df.head(10))\n",
    "\n",
    "print(\"\\nFeature Statistics:\")\n",
    "feature_cols = [col for col in features_df.columns if any(x in col for x in ['mfcc', 'spectral', 'rms', 'zero', 'chroma'])]\n",
    "display(features_df[feature_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbedf14",
   "metadata": {},
   "source": [
    "## 7. Process Unauthorized Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "unauthorized_files = list(unauthorized_dir.glob('*.wav'))\n",
    "\n",
    "print(f\"Found {len(unauthorized_files)} unauthorized samples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(unauthorized_files) > 0:\n",
    "    for audio_file in unauthorized_files:\n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "        features = extract_audio_features(y, sr)\n",
    "        features.update({\n",
    "            'filename': audio_file.name,\n",
    "            'member': 'unauthorized',\n",
    "            'phrase': 'unknown',\n",
    "            'augmentation': 'original',\n",
    "            'is_authorized': 0\n",
    "        })\n",
    "        all_features.append(features)\n",
    "        print(f\"[OK] {audio_file.name}\")\n",
    "    \n",
    "    features_df = pd.DataFrame(all_features)\n",
    "    print(f\"\\nTotal samples: {len(features_df)} (authorized + unauthorized)\")\n",
    "else:\n",
    "    print(\"WARNING: No unauthorized samples found\")\n",
    "    print(f\"   Add to: {unauthorized_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eea565",
   "metadata": {},
   "source": [
    "## 8. Save audio_features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = base_dir / 'Dataset' / 'audio_features.csv'\n",
    "features_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved: {output_path}\")\n",
    "print(f\"   Shape: {features_df.shape}\")\n",
    "print(f\"   Columns: {len(features_df.columns)}\")\n",
    "print(\"audio_features.csv created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f9e23",
   "metadata": {},
   "source": [
    "## 9. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac573d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUDIO FEATURES EDA\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nDataset Info:\")\n",
    "features_df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Authorization Distribution:\")\n",
    "print(features_df['is_authorized'].value_counts())\n",
    "\n",
    "print(\"\\nMember Distribution:\")\n",
    "print(features_df['member'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    mfcc_col = f'mfcc_{i+1}_mean'\n",
    "    if mfcc_col in features_df.columns:\n",
    "        features_df.boxplot(column=mfcc_col, by='member', ax=ax)\n",
    "        ax.set_title(f'MFCC {i+1} by Member')\n",
    "        ax.set_xlabel('Member')\n",
    "        ax.set_ylabel(f'MFCC {i+1} Mean')\n",
    "\n",
    "plt.suptitle('MFCC Features Distribution', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f554c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['mfcc_1_mean', 'mfcc_2_mean', 'spectral_rolloff_mean', 'rms_energy_mean', \n",
    "                     'zero_crossing_rate_mean', 'spectral_centroid_mean', 'chroma_mean']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation = features_df[selected_features].corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "features_df.boxplot(column='rms_energy_mean', by='is_authorized', ax=axes[0])\n",
    "axes[0].set_title('RMS Energy: Authorized vs Unauthorized')\n",
    "axes[0].set_xlabel('Is Authorized (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('RMS Energy Mean')\n",
    "\n",
    "features_df.boxplot(column='spectral_rolloff_mean', by='is_authorized', ax=axes[1])\n",
    "axes[1].set_title('Spectral Rolloff: Authorized vs Unauthorized')\n",
    "axes[1].set_xlabel('Is Authorized (0=No, 1=Yes)')\n",
    "axes[1].set_ylabel('Spectral Rolloff Mean')\n",
    "\n",
    "features_df.boxplot(column='mfcc_1_mean', by='is_authorized', ax=axes[2])\n",
    "axes[2].set_title('MFCC 1: Authorized vs Unauthorized')\n",
    "axes[2].set_xlabel('Is Authorized (0=No, 1=Yes)')\n",
    "axes[2].set_ylabel('MFCC 1 Mean')\n",
    "\n",
    "plt.suptitle('Authorized vs Unauthorized Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf9414",
   "metadata": {},
   "source": [
    "## 10. Voiceprint Verification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44be965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL DEVELOPMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "feature_columns = [col for col in features_df.columns if any(x in col for x in \n",
    "                   ['mfcc', 'spectral', 'rms', 'zero', 'chroma'])]\n",
    "\n",
    "X = features_df[feature_columns]\n",
    "y = features_df['is_authorized']\n",
    "\n",
    "print(f\"Features: {X.shape} | Target: {y.shape}\")\n",
    "print(f\"Class distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131990ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {X_train_scaled.shape} | Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Models...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}: Accuracy={results[model_name]['accuracy']:.4f}, F1={results[model_name]['f1_score']:.4f}\")\n",
    "\n",
    "print(\"\\nModels trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f} | F1-Score: {result['f1_score']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, result['predictions'], labels=[0, 1], target_names=['Unauthorized', 'Authorized'], zero_division=0))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, result['predictions'], labels=[0, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Unauthorized', 'Authorized'],\n",
    "                yticklabels=['Unauthorized', 'Authorized'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1340be",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {results[best_model_name]['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5f161",
   "metadata": {},
   "source": [
    "## 11. Save Model & Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = base_dir / 'models'\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = model_dir / 'voiceprint_model.pkl'\n",
    "scaler_path = model_dir / 'audio_scaler.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"Saved:\\n   Model: {model_path}\\n   Scaler: {scaler_path}\")\n",
    "print(\"Ready for system integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be27c76",
   "metadata": {},
   "source": [
    "## 12. Verification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_voiceprint(audio_path, model, scaler):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        features = extract_audio_features(y, sr)\n",
    "        feature_vector = pd.DataFrame([features])[feature_columns]\n",
    "        feature_vector_scaled = scaler.transform(feature_vector)\n",
    "        \n",
    "        prediction = model.predict(feature_vector_scaled)[0]\n",
    "        confidence = model.predict_proba(feature_vector_scaled)[0]\n",
    "        \n",
    "        return {\n",
    "            'authorized': bool(prediction),\n",
    "            'confidence': float(confidence[prediction]),\n",
    "            'message': 'Voice verified - Access granted' if prediction else 'Voice not recognized - Access denied'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'authorized': False,\n",
    "            'confidence': 0.0,\n",
    "            'message': f'Verification failed: {str(e)}'\n",
    "        }\n",
    "\n",
    "print(\"Verification function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20da67d",
   "metadata": {},
   "source": [
    "## 13. Test Verification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TESTING VOICEPRINT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAuthorized Samples:\")\n",
    "\n",
    "test_authorized = audio_files[:2] if len(audio_files) >= 2 else audio_files\n",
    "\n",
    "for audio_path in test_authorized:\n",
    "    result = verify_voiceprint(audio_path, best_model, scaler)\n",
    "    status = 'APPROVED' if result['authorized'] else 'DENIED'\n",
    "    print(f\"{audio_path.name}: {status} ({result['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnauthorized Samples:\")\n",
    "\n",
    "if len(unauthorized_files) > 0:\n",
    "    for audio_path in unauthorized_files:\n",
    "        result = verify_voiceprint(audio_path, best_model, scaler)\n",
    "        status = 'APPROVED' if result['authorized'] else 'DENIED'\n",
    "        print(f\"{audio_path.name}: {status} ({result['confidence']:.2%})\")\n",
    "else:\n",
    "    print(\"WARNING: No unauthorized samples to test\")\n",
    "\n",
    "print(\"\\nVerification testing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c9047",
   "metadata": {},
   "source": [
    "## 14. Deliverables Summary\n",
    "\n",
    "### Completed:\n",
    "- Audio data collection and organization\n",
    "- Waveform and spectrogram visualizations\n",
    "- 4 augmentations per sample\n",
    "- Feature extraction (MFCCs, spectral features, energy)\n",
    "- `audio_features.csv` saved\n",
    "- Voiceprint verification model trained and evaluated\n",
    "- `voiceprint_model.pkl` and `audio_scaler.pkl` saved\n",
    "- Verification function for system integration\n",
    "\n",
    "### Files Created:\n",
    "- `Dataset/audio_features.csv`\n",
    "- `models/voiceprint_model.pkl`\n",
    "- `models/audio_scaler.pkl`\n",
    "- Augmented audio samples in `Dataset/audio_samples/augmented/`\n",
    "\n",
    "### Next Steps:\n",
    "1. Add unauthorized samples (if not done)\n",
    "2. Integrate with face recognition and product recommendation models\n",
    "3. Build command-line application\n",
    "4. Create demonstration video\n",
    "5. Write final report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
