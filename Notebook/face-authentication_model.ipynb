{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68887108",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1611736120.py, line 17)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport osos.makedirs(MODELS_DIR, exist_ok=True)\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import traceback\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define models directory path\n",
    "MODELS_DIR = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), 'models'))\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7da43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (48, 1282)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aubert_neutral.jpeg</td>\n",
       "      <td>Aubert</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.445374</td>\n",
       "      <td>0.138666</td>\n",
       "      <td>0.199406</td>\n",
       "      <td>0.234222</td>\n",
       "      <td>1.502202</td>\n",
       "      <td>0.550103</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860995</td>\n",
       "      <td>2.957347</td>\n",
       "      <td>2.697805</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.845628</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0.069172</td>\n",
       "      <td>2.189625</td>\n",
       "      <td>0.300332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aubert_smiling.jpeg</td>\n",
       "      <td>Aubert</td>\n",
       "      <td>0.333226</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.778736</td>\n",
       "      <td>0.052578</td>\n",
       "      <td>1.230657</td>\n",
       "      <td>0.227494</td>\n",
       "      <td>0.366348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628935</td>\n",
       "      <td>1.751879</td>\n",
       "      <td>2.301380</td>\n",
       "      <td>0.268388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576595</td>\n",
       "      <td>0.187293</td>\n",
       "      <td>0.178212</td>\n",
       "      <td>1.706536</td>\n",
       "      <td>0.716214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aubert_surprised.jpeg</td>\n",
       "      <td>Aubert</td>\n",
       "      <td>0.247052</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.388474</td>\n",
       "      <td>0.917524</td>\n",
       "      <td>0.082370</td>\n",
       "      <td>0.932131</td>\n",
       "      <td>0.371109</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407668</td>\n",
       "      <td>1.974943</td>\n",
       "      <td>2.590067</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847615</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.075061</td>\n",
       "      <td>1.090720</td>\n",
       "      <td>0.925528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jade_neutral.jpeg</td>\n",
       "      <td>Jade</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.079102</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882140</td>\n",
       "      <td>0.652241</td>\n",
       "      <td>1.449127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.267299</td>\n",
       "      <td>0.540980</td>\n",
       "      <td>0.071052</td>\n",
       "      <td>0.891298</td>\n",
       "      <td>0.545639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jade_smiling.jpeg</td>\n",
       "      <td>Jade</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095859</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.404002</td>\n",
       "      <td>0.227005</td>\n",
       "      <td>0.957205</td>\n",
       "      <td>0.154348</td>\n",
       "      <td>1.643815</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284185</td>\n",
       "      <td>0.727041</td>\n",
       "      <td>2.619657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>0.630383</td>\n",
       "      <td>0.139690</td>\n",
       "      <td>0.729029</td>\n",
       "      <td>0.044618</td>\n",
       "      <td>0.548145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename   label         0         1         2         3  \\\n",
       "0    Aubert_neutral.jpeg  Aubert  0.592436  0.445374  0.138666  0.199406   \n",
       "1    Aubert_smiling.jpeg  Aubert  0.333226  0.010147  0.001928  0.778736   \n",
       "2  Aubert_surprised.jpeg  Aubert  0.247052  0.007888  0.388474  0.917524   \n",
       "3      Jade_neutral.jpeg    Jade  0.000000  0.130793  0.000000  0.497212   \n",
       "4      Jade_smiling.jpeg    Jade  0.000000  1.095859  0.020419  0.404002   \n",
       "\n",
       "          4         5         6         7  ...      1270      1271      1272  \\\n",
       "0  0.234222  1.502202  0.550103  0.029583  ...  0.860995  2.957347  2.697805   \n",
       "1  0.052578  1.230657  0.227494  0.366348  ...  0.628935  1.751879  2.301380   \n",
       "2  0.082370  0.932131  0.371109  0.423742  ...  0.407668  1.974943  2.590067   \n",
       "3  0.000000  1.079102  0.007094  0.659984  ...  0.882140  0.652241  1.449127   \n",
       "4  0.227005  0.957205  0.154348  1.643815  ...  1.284185  0.727041  2.619657   \n",
       "\n",
       "       1273      1274      1275      1276      1277      1278      1279  \n",
       "0  0.051768  0.002270  0.845628  0.095015  0.069172  2.189625  0.300332  \n",
       "1  0.268388  0.000000  0.576595  0.187293  0.178212  1.706536  0.716214  \n",
       "2  0.006534  0.000000  0.847615  0.058786  0.075061  1.090720  0.925528  \n",
       "3  0.000000  0.124035  0.267299  0.540980  0.071052  0.891298  0.545639  \n",
       "4  0.000000  0.081618  0.630383  0.139690  0.729029  0.044618  0.548145  \n",
       "\n",
       "[5 rows x 1282 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape (before conversion): (48, 1280)\n",
      "Classes: ['Aubert', 'Jade', 'Liliane', 'Pauline']\n",
      "Train shape: (38, 1280) Test shape: (10, 1280)\n",
      "\n",
      "Model training completed\n",
      "\n",
      "Test accuracy: 1.0000  weighted F1: 1.0000  log loss: 0.1102\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Aubert       1.00      1.00      1.00         3\n",
      "        Jade       1.00      1.00      1.00         2\n",
      "     Liliane       1.00      1.00      1.00         3\n",
      "     Pauline       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "Saved: face_auth_logreg.joblib, face_auth_scaler.joblib, face_auth_label_encoder.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\alumachinelearning\\year3 ALU\\formative2\\Group_5_Multimodal-Data-Preprocessing-Assignment\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# STEP 1-3: Load data, preprocess, train and evaluate Logistic Regression (leakage-free)\n",
    "csv_path = 'image_features_clean.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV not found: {csv_path} - run the extraction cell first\")\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(csv_path)\n",
    "print('CSV shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Determine label column\n",
    "if 'label' in df.columns:\n",
    "    y_raw = df['label'].astype(str)\n",
    "elif 'filename' in df.columns:\n",
    "    y_raw = df['filename'].astype(str).apply(lambda s: s.split('_')[0])\n",
    "else:\n",
    "    raise ValueError(\"CSV must contain a 'label' or 'filename' column to derive identity labels\")\n",
    "\n",
    "# Build feature matrix X: drop filename/label if present\n",
    "X_df = df.drop(columns=[c for c in ['filename','label'] if c in df.columns])\n",
    "print('Feature matrix shape (before conversion):', X_df.shape)\n",
    "\n",
    "# Ensure numeric\n",
    "non_numeric = [c for c in X_df.columns if not pd.api.types.is_numeric_dtype(X_df[c])]\n",
    "if non_numeric:\n",
    "    raise ValueError(f\"Non-numeric feature columns found: {non_numeric}\")\n",
    "\n",
    "X = X_df.astype(np.float32).values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "print('Classes:', list(le.classes_))\n",
    "\n",
    "# Train/test split (stratify) BEFORE scaling to avoid leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Scale features: fit scaler on train only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs')\n",
    "try:\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print('\\nModel training completed')\n",
    "except Exception:\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "probs = model.predict_proba(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "loss = log_loss(y_test, probs, labels=model.classes_)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}  weighted F1: {f1:.4f}  log loss: {loss:.4f}\")\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Save model + preprocessing (joblib) to models directory\n",
    "joblib.dump(model, os.path.join(MODELS_DIR, 'face_auth_logreg.joblib'))\n",
    "joblib.dump(scaler, os.path.join(MODELS_DIR, 'face_auth_scaler.joblib'))\n",
    "joblib.dump(le, os.path.join(MODELS_DIR, 'face_auth_label_encoder.joblib'))\n",
    "print(f'Saved models to {MODELS_DIR}: face_auth_logreg.joblib, face_auth_scaler.joblib, face_auth_label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not available or failed to train: No module named 'xgboost'\n",
      "                model  accuracy  f1_weighted  log_loss\n",
      "0  LogisticRegression       1.0     1.000000  0.110218\n",
      "1        RandomForest       0.8     0.783333  0.755667\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: Random Forest and XGBoost (if available)\n",
    "results = []\n",
    "# Append logistic regression metrics (from previous cell)\n",
    "try:\n",
    "    results.append(('LogisticRegression', acc, f1, loss))\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "probs_rf = rf.predict_proba(X_test_scaled)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "loss_rf = log_loss(y_test, probs_rf, labels=rf.classes_)\n",
    "results.append(('RandomForest', acc_rf, f1_rf, loss_rf))\n",
    "joblib.dump(rf, os.path.join(MODELS_DIR, 'face_auth_rf.joblib'))\n",
    "\n",
    "# Try XGBoost if available\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    xgb_clf.fit(X_train_scaled, y_train)\n",
    "    y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "    probs_xgb = xgb_clf.predict_proba(X_test_scaled)\n",
    "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "    loss_xgb = log_loss(y_test, probs_xgb, labels=xgb_clf.classes_)\n",
    "    results.append(('XGBoost', acc_xgb, f1_xgb, loss_xgb))\n",
    "    joblib.dump(xgb_clf, os.path.join(MODELS_DIR, 'face_auth_xgboost.joblib'))\n",
    "except Exception as e:\n",
    "    print('XGBoost not available or failed to train:', e)\n",
    "\n",
    "# Show results summary\n",
    "df_results = pd.DataFrame(results, columns=['model','accuracy','f1_weighted','log_loss'])\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ac3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: face_recognition_model.joblib, known_features.npz\n"
     ]
    }
   ],
   "source": [
    "# Save alternate model filename and known training features to models directory\n",
    "joblib.dump(model, os.path.join(MODELS_DIR, \"face_recognition_model.joblib\"))\n",
    "np.savez_compressed(os.path.join(MODELS_DIR, \"known_features.npz\"), X_train=X_train, y_train=y_train)\n",
    "print(f'Saved to {MODELS_DIR}: face_recognition_model.joblib, known_features.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNet model and helpers\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB').resize((224, 224))\n",
    "        img_array = np.array(img)\n",
    "        img_array = preprocess_input(img_array.astype(np.float32))\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(\" Error loading image:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_unseen_face(img_path, distance_threshold=0.6):\n",
    "    print(f\"\\n Testing on image: {os.path.basename(img_path)}\")\n",
    "\n",
    "    img_tensor = load_and_preprocess_image(img_path)\n",
    "    if img_tensor is None:\n",
    "        return\n",
    "\n",
    "    # Load classifier (try alternate filenames) from models directory\n",
    "    model = None\n",
    "    for candidate in ['face_recognition_model.joblib', 'face_auth_logreg.joblib', 'face_auth_rf.joblib']:\n",
    "        try:\n",
    "            model_path = os.path.join(MODELS_DIR, candidate)\n",
    "            model = joblib.load(model_path)\n",
    "            print(f\"Loaded model: {model_path}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if model is None:\n",
    "        raise FileNotFoundError(\"No trained model found. Run the training cell first.\")\n",
    "\n",
    "    # Load known features (npz) if available from models directory\n",
    "    known_features = None\n",
    "    known_labels = None\n",
    "    known_features_path = os.path.join(MODELS_DIR, 'known_features.npz')\n",
    "    if os.path.exists(known_features_path):\n",
    "        data = np.load(known_features_path)\n",
    "        known_features = data['X_train']\n",
    "        known_labels = data['y_train']\n",
    "    else:\n",
    "        print('No known features file found; distance check will be skipped')\n",
    "\n",
    "    # Load label encoder if present from models directory\n",
    "    le_local = None\n",
    "    le_path = os.path.join(MODELS_DIR, 'face_auth_label_encoder.joblib')\n",
    "    if os.path.exists(le_path):\n",
    "        try:\n",
    "            le_local = joblib.load(le_path)\n",
    "        except Exception:\n",
    "            le_local = None\n",
    "\n",
    "    # Step 1: Extract features\n",
    "    feature_vector = mobilenet_model.predict(img_tensor)[0]\n",
    "\n",
    "    # Step 2: Predict class using classifier\n",
    "    probs = model.predict_proba(np.expand_dims(feature_vector, axis=0))[0]\n",
    "    predicted_index = int(np.argmax(probs))\n",
    "    predicted_class = model.classes_[predicted_index]\n",
    "    confidence = float(probs[predicted_index])\n",
    "\n",
    "    print(\"\\n Prediction Probabilities:\")\n",
    "    for cls, prob in zip(model.classes_, probs):\n",
    "        name = cls\n",
    "        if le_local is not None and isinstance(cls, (int, np.integer)):\n",
    "            try:\n",
    "                name = le_local.inverse_transform([cls])[0]\n",
    "            except Exception:\n",
    "                name = cls\n",
    "        print(f\"{name}: {prob:.2f}\")\n",
    "\n",
    "    decoded_pred = predicted_class\n",
    "    if le_local is not None and isinstance(predicted_class, (int, np.integer)):\n",
    "        try:\n",
    "            decoded_pred = le_local.inverse_transform([predicted_class])[0]\n",
    "        except Exception:\n",
    "            decoded_pred = predicted_class\n",
    "\n",
    "    print(f\"\\n Predicted: {decoded_pred}\")\n",
    "    print(f\" Confidence: {confidence:.2f}\")\n",
    "\n",
    "    # Step 3: Distance check to known features (optional)\n",
    "    if known_features is not None:\n",
    "        distances = [euclidean(feature_vector, known_vec) for known_vec in known_features]\n",
    "        min_distance = float(np.min(distances))\n",
    "        closest_idx = int(np.argmin(distances))\n",
    "        closest_label = known_labels[closest_idx]\n",
    "        closest_name = closest_label\n",
    "        if le_local is not None:\n",
    "            try:\n",
    "                closest_name = le_local.inverse_transform([int(closest_label)])[0]\n",
    "            except Exception:\n",
    "                closest_name = closest_label\n",
    "        print(f\" Min Distance to known face: {min_distance:.4f}\")\n",
    "        print(f\" Closest to: {closest_name}\")\n",
    "        if min_distance < distance_threshold:\n",
    "            print(f\" Access Granted to: {decoded_pred}\")\n",
    "        else:\n",
    "            print(\" Access Denied: Unknown user\")\n",
    "    else:\n",
    "        print('Distance check skipped (no known features)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found test image: member2.jpeg, running test_on_unseen_face\n",
      "\n",
      " Testing on image: member2.jpeg\n",
      "Loaded model: face_recognition_model.joblib\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      " Prediction Probabilities:\n",
      "Aubert: 0.26\n",
      "Jade: 0.14\n",
      "Liliane: 0.39\n",
      "Pauline: 0.21\n",
      "\n",
      " Predicted: Liliane\n",
      " Confidence: 0.39\n",
      " Min Distance to known face: 20.1762\n",
      " Closest to: Aubert\n",
      " Access Denied: Unknown user\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      " Prediction Probabilities:\n",
      "Aubert: 0.26\n",
      "Jade: 0.14\n",
      "Liliane: 0.39\n",
      "Pauline: 0.21\n",
      "\n",
      " Predicted: Liliane\n",
      " Confidence: 0.39\n",
      " Min Distance to known face: 20.1762\n",
      " Closest to: Aubert\n",
      " Access Denied: Unknown user\n"
     ]
    }
   ],
   "source": [
    "# Quick automatic test: run on member2.jpeg if present\n",
    "test_img = 'member2.jpeg'\n",
    "if os.path.exists(test_img):\n",
    "    print(f'Found test image: {test_img}, running test_on_unseen_face')\n",
    "    try:\n",
    "        test_on_unseen_face(test_img)\n",
    "    except Exception as e:\n",
    "        print('Error during test_on_unseen_face:', e)\n",
    "else:\n",
    "    print(\"No test image 'member2.jpeg' found. Update the path or add your test image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813fd962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found test image: Jade_neutral.jpeg, running test_on_unseen_face\n",
      "\n",
      " Testing on image: Jade_neutral.jpeg\n",
      "Loaded model: face_recognition_model.joblib\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\n",
      " Prediction Probabilities:\n",
      "Aubert: 0.05\n",
      "Jade: 0.82\n",
      "Liliane: 0.08\n",
      "Pauline: 0.04\n",
      "\n",
      " Predicted: Jade\n",
      " Confidence: 0.82\n",
      " Min Distance to known face: 0.0000\n",
      " Closest to: Jade\n",
      " Access Granted to: Jade\n",
      "\n",
      " Prediction Probabilities:\n",
      "Aubert: 0.05\n",
      "Jade: 0.82\n",
      "Liliane: 0.08\n",
      "Pauline: 0.04\n",
      "\n",
      " Predicted: Jade\n",
      " Confidence: 0.82\n",
      " Min Distance to known face: 0.0000\n",
      " Closest to: Jade\n",
      " Access Granted to: Jade\n"
     ]
    }
   ],
   "source": [
    "# Quick automatic test: run on member2.jpeg if present\n",
    "test_img = 'Jade_neutral.jpeg'\n",
    "if os.path.exists(test_img):\n",
    "    print(f'Found test image: {test_img}, running test_on_unseen_face')\n",
    "    try:\n",
    "        test_on_unseen_face(test_img)\n",
    "    except Exception as e:\n",
    "        print('Error during test_on_unseen_face:', e)\n",
    "else:\n",
    "    print(\"No test image 'member2.jpeg' found. Update the path or add your test image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
