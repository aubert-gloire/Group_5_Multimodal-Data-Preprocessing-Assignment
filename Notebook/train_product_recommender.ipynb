{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "gl8SJhKA-Vrd",
        "outputId": "3760f906-5772-4ec9-d472-c833b13aa6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from c:\\Users\\evotech\\Documents\\MACHINE LEARNING PROJECTS\\Group_5_Multimodal-Data-Preprocessing-Assignment\\Dataset\\merged_customer_data.csv\n",
            "Rows, cols: (213, 12)\n",
            "Distinct product classes: 5\n",
            "Numeric features: ['engagement_score', 'purchase_interest_score', 'customer_id', 'customer_id_legacy', 'purchase_amount', 'customer_rating', 'purchase_month', 'purchase_day', 'mean_purchase_amount', 'transaction_count']\n",
            "Categorical features: ['customer_id_new', 'social_media_platform', 'review_sentiment']\n",
            "Numeric features: ['engagement_score', 'purchase_interest_score', 'customer_id', 'customer_id_legacy', 'purchase_amount', 'customer_rating', 'purchase_month', 'purchase_day', 'mean_purchase_amount', 'transaction_count']\n",
            "Categorical features: ['customer_id_new', 'social_media_platform', 'review_sentiment']\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCategorical features:\u001b[39m\u001b[33m'\u001b[39m, categorical_features)\n\u001b[32m     69\u001b[39m numeric_transformer = Pipeline([(\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m, StandardScaler())])\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m categorical_transformer = \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m preprocessor = ColumnTransformer([(\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, numeric_transformer, numeric_features), (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, categorical_transformer, categorical_features)])\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Full pipeline\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
          ]
        }
      ],
      "source": [
        "# Train product recommender on the merged dataset and save artifacts for the CLI\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, classification_report, confusion_matrix\n",
        "\n",
        "# Paths and config\n",
        "NOTEBOOK_DIR = Path.cwd()\n",
        "ROOT = NOTEBOOK_DIR.parent\n",
        "DATA_PATH = ROOT / 'Dataset' / 'merged_customer_data.csv'\n",
        "MODELS_DIR = ROOT / 'models'\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "TARGET_COL = 'product_category'\n",
        "\n",
        "# Load dataset\n",
        "print('Loading dataset from', DATA_PATH)\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print('Rows, cols:', df.shape)\n",
        "\n",
        "# Simple feature engineering\n",
        "if 'purchase_date' in df.columns:\n",
        "    df['purchase_date'] = pd.to_datetime(df['purchase_date'], errors='coerce')\n",
        "    df['purchase_month'] = df['purchase_date'].dt.month.fillna(0).astype(int)\n",
        "    df['purchase_day'] = df['purchase_date'].dt.day.fillna(0).astype(int)\n",
        "else:\n",
        "    df['purchase_month'] = 0\n",
        "    df['purchase_day'] = 0\n",
        "\n",
        "cust_id_col = next((c for c in ['customer_id_new', 'customer_id', 'customer_id_legacy'] if c in df.columns), None)\n",
        "if cust_id_col is not None:\n",
        "    agg = df.groupby(cust_id_col)['purchase_amount'].agg(mean_purchase_amount='mean', transaction_count='count').reset_index()\n",
        "    df = df.merge(agg, on=cust_id_col, how='left')\n",
        "else:\n",
        "    df['mean_purchase_amount'] = df.get('purchase_amount', pd.Series(0))\n",
        "    df['transaction_count'] = 1\n",
        "\n",
        "# Ensure target exists and drop rows without it\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise KeyError(f\"Target column '{TARGET_COL}' not found. Columns: {list(df.columns)}\")\n",
        "df = df.dropna(subset=[TARGET_COL]).copy()\n",
        "\n",
        "# Prepare X, y\n",
        "X = df.drop(columns=[TARGET_COL])\n",
        "y = df[TARGET_COL]\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print('Distinct product classes:', len(label_encoder.classes_))\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Preprocessor: auto-detect numeric/categorical\n",
        "numeric_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
        "for bad in ['transaction_id']:\n",
        "    if bad in numeric_features: numeric_features.remove(bad)\n",
        "    if bad in categorical_features: categorical_features.remove(bad)\n",
        "print('Numeric features:', numeric_features)\n",
        "print('Categorical features:', categorical_features)\n",
        "\n",
        "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "preprocessor = ColumnTransformer([('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Full pipeline\n",
        "clf = Pipeline([('preprocessor', preprocessor), ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))])\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "y_proba = clf.predict_proba(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "ll = log_loss(y_test, y_proba)\n",
        "\n",
        "print('\\n=== PRODUCT RECOMMENDATION MODEL PERFORMANCE ===')\n",
        "print(f'Accuracy : {acc:.4f}')\n",
        "print(f'F1-macro : {f1_macro:.4f}')\n",
        "print(f'Log Loss : {ll:.4f}')\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print('\\nConfusion matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Save artifacts to models/ directory\n",
        "pipeline_path = MODELS_DIR / 'product_recommendation_pipeline.joblib'\n",
        "encoder_path = MODELS_DIR / 'product_label_encoder.joblib'\n",
        "joblib.dump(clf, str(pipeline_path))\n",
        "joblib.dump(label_encoder, str(encoder_path))\n",
        "print(f'\\nSaved pipeline to {pipeline_path}')\n",
        "print(f'Saved label encoder to {encoder_path}')\n",
        "\n",
        "# Helper function for CLI (loads saved artifacts)\n",
        "def recommend_products_from_features(features_dict, top_k=3):\n",
        "    \"\"\"Load trained model and return top-k product recommendations\"\"\"\n",
        "    pipe = joblib.load(str(pipeline_path))\n",
        "    label_enc = joblib.load(str(encoder_path))\n",
        "    X_user = pd.DataFrame([features_dict])\n",
        "    proba = pipe.predict_proba(X_user)[0]\n",
        "    classes = np.arange(len(proba))\n",
        "    labels = label_enc.inverse_transform(classes)\n",
        "    idx_sorted = np.argsort(proba)[::-1][:top_k]\n",
        "    recommendations = [(labels[i], float(proba[i])) for i in idx_sorted]\n",
        "    return recommendations\n",
        "\n",
        "print('\\n--- Example usage in CLI after auth:')\n",
        "print('recs = recommend_products_from_features({...user features...}, top_k=3)')\n",
        "print('Training complete!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
